# # This code was generated by CHATGPT3.5 with some modifications

## Long short term memory for continuous data

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

# Read data from Excel file
df = pd.read_excel('LSTM_cont_raw.xlsx')  # Replace 'your_excel_file.xlsx' with the path to your Excel file

# Normalize the data using Min-Max scaling
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df.values)

# Define a function to prepare data for LSTM
def prepare_data(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:(i + time_steps), 0])
        # print(data[i:(i + time_steps), 0])
        y.append(data[i + time_steps, 0])
        # print(data[i + time_steps, 0])
    return np.array(X), np.array(y)

# Define the number of time steps (e.g., past days' prices to consider)
time_steps = 42

# Prepare the data for LSTM
X, y = prepare_data(scaled_data, time_steps)

# Split the data into training and test sets
split_ratio = 0.8
split_index = int(split_ratio * len(X))
X_train, X_test = X[:split_index], X[split_index:]
# print(X_train)
# print(X_test)
y_train, y_test = y[:split_index], y[split_index:]

# Reshape the data for LSTM input (samples, time steps, features)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Define the LSTM model
model = tf.keras.Sequential([
    tf.keras.layers.LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.LSTM(100, return_sequences=False),
    tf.keras.layers.Dense(25),
    tf.keras.layers.Dense(1)
])

# Compile the model with SGD optimizer
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)  # Gradient descent optimizer
model.compile(optimizer=optimizer, loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=30, batch_size=128)

# Evaluate the model
test_loss = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}')

# Make predictions
predictions = model.predict(X_test)

# Rescale predictions and actual values
predictions = scaler.inverse_transform(predictions)
y_test = scaler.inverse_transform(y_test.reshape(-1, 1))

# Create a DataFrame to store predictions and actual values
results_df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': predictions.flatten()})

# Save DataFrame to Excel
results_df.to_excel('LSTM_cont_stock_price_predictions.xlsx', index=False)

# Calculate MSE using sklearn
test_mse_sklearn = mean_squared_error(y_test, predictions)
print(f'Test MSE (calculated using sklearn): {test_mse_sklearn}')

# Calculate MSE manually
test_mse_manual = np.mean((y_test - predictions) ** 2)
print(f'Test MSE (calculated manually): {test_mse_manual}')

